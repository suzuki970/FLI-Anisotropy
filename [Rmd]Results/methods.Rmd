---
title: "method"
author: "Yuta Suzuki"
date: "3/2/2022"
output: html_document
---

```{r, message=FALSE, echo=FALSE,warning=FALSE,include=FALSE}
dat <- read.xlsx("../[Python]PreProcessing/results/subInfo.xlsx")

numOfSub = dim(dat)[1]
meanAge = round(mean(dat[!is.na(dat$age),]$age),2)
sdAge = round(sd(dat[!is.na(dat$age),]$age),2)
numOfMen = length(which(dat[!is.na(dat$gender),]$gender == 'M'))
numOfWomen = length(which(dat[!is.na(dat$gender),]$gender == 'F'))

ind_data$numOfTrials = 0
for(iSub in sort(unique(ind_data$sub))){
  for(iLag in sort(unique(ind_data$SOA))){
    for(ivField in sort(unique(ind_data$vField))){
      d = ind_data[ind_data$sub == iSub &
                     ind_data$SOA == iLag &
                     ind_data$vField == ivField,]
      if (dim(d)[1] > 0){
      ind_data[ind_data$sub == iSub &
                 ind_data$SOA == iLag &
                 ind_data$vField == ivField,]$numOfTrials = dim(d)[1]
    }
    }
  }
}
tmp = aggregate( . ~ sub*SOA*vField, data = ind_data, FUN = "mean")
tmp$diff = 10-tmp$numOfTrials


rejectedNum = numOfSub - length(unique(ind_data$sub))
rejectedNumName = c("One","Two","Three","Four","Five","Six","Seven","Eight","Nine")

```

# Methods
### Participants
Seventy-three volunteers (`r numOfMen` men; `r numOfWomen` women; mean age = `r meanAge`, SD = `r sdAge`), with a normal or corrected-to-normal vision, participated in the experiment. `r rejectedNumName[rejectedNum]` participants were excluded from the analyses because their responses failed to fit a psychometric curve (see Statistical Analysis section). Another three participants were excluded due to invalid sampling in more than 40% of a whole trial. The experiment lasted approximately 15 min, and all participants were compensated for their time (100 NOK or ≈ 10 Euros). All experimental procedures were in accordance with the ethical principles outlined in the Declaration of Helsinki and approved by the Ethical Committee at the Department of Psychology, University of Oslo. All participants provided written informed consent. Participants’ data and experimental scripts are available from https://github.com/suzuki970/FLI-Anisotropy.
\

### Stimulus and apparatus
The xy coordinates of the background and objects were 0.350 and 0.365 in the CIE1931 color space. The luminance of the stimuli was calibrated using a Spyder 4 Elite photometer (Datacolor Imaging Solutions, Lawrenceville, NJ), which indicated the background was 28.41 cd/m2. The luminance of the flashed and moving bars was 71.66 cd/m2. All stimuli were presented on a 22 in. LCD monitor (P2210, Dell., Round Rock, US) with a resolution of 1680 x 1050 and a refresh rate of 60 Hz. The visual angle of the flashed and moving bars were 1.5° x 0.1° and 1.0° x 0.1° respectively. The trajectory of the moving bar was from 4.5° to 2.5° away from the center of the monitor. The bar moved horizontally toward within 500 ms so that the moving speed was 4°/s. The flashed object was located at 2.5° x 2.75° from the center. A fixation point of 0.2° was located at the center. Each participant’s head and point of regard were kept constant by use of a chinrest at a viewing distance of 600 mm from the screen and an eye-tracking infrared camera. The task was conducted in a darkroom and executed by Experiment Center (SMI, Berlin, Germany).
\

### Procedure
Figure 1 illustrates the experimental procedure. In each trial, a fixation point was presented for 2,000 ms prior to the presentation of the stimulus. The moving bar appeared at left/right for 50 ms and then started moving toward the center of the screen. During the presentation, the flashed bar could appear at eight different stimulus onset asynchrony (SOA) conditions of -83.3, -66.7, -50.0, -33.3, -16.7, 0.0, 16.7, and 33.3 ms relative to the middle of presentation (i.e., 250 ms) and for 16 ms. Then, participants answered whether they perceived the moving bar at the left or right of the flashed bar using a keypad (Figure 1A). Each trial was separated by an inter-stimulus interval (ISI) of 2,000 ms. The experiment began with a five-point eye calibration. In the first block, the stimulus was presented on the LVF side of the screen for half of the participants and on the RVF for another half. The second block tested the opposite visual field. Thus, a total number of trials were 160 (2 visual VFs × 8 SOA × 10 repetitions).
\

### Recording and analysis of pupil size
Pupil size and gaze position were measured by a SensoMotoric Instruments RED500 (SMI, Berlin, Germany) eye-tracking system at a sampling rate of 60 Hz and at a resolution of about 0.01°. Pupil data during eye-blinks, obtained as the values of zero in the data and more than ±3 standard deviation of the first derivative of pupil data within each session and participant, were interpolated by piecewise cubic Hermite interpolation.

The analyses in the present study were based on pupil diameters calculated in z-score (z) within the session for each participant. Trials including pupil changes of more than 18 (z)/s were excluded from the analysis. Gaze fixations were counted during the trial with the following algorithm: eye-gazes staying at less than < 1° and their duration > 100ms were regarded as a gaze-fixation. Each gaze fixation position × duration was averaged within the trial and referred to as the averaged gaze-fixation. The trial including the averaged gaze-fixation in more than ± 4.5° (i.e., the initial stimulus position) was excluded from the analysis. RTs at more than 3s (i.e., the period from presentation offset to next trial onset).
The mean rejected trials were `r round(mean(tmp$diff),3)` and SD = `r round(sd(tmp$diff),3)` out of 10 trials. 

Since there was more than 80 % data loss due to eye-blinks or eye-tracker dependent causes after 3.22 s from stimulus onset (see Supplementary Figure 1A), we limited the analyses to the initial 2 s. The baseline pupil size was computed as an average of data collected from -500 ms to 0 ms relative to the task onset. The pupillary data in each trial were baseline-corrected by subtracting the baseline pupil size, following which smoothing of each data point with ± 33 ms. Then, the pupillary responses were averaged across conditions from the task response to 2 s.

To assess the velocity of the pupillary change return to the baseline level, we first calculated the local peak pupil dilation and constriction during the trial. After pupil changes were grand-averaged across all conditions, pupil slopes were computed using second-order central differences. Peak pupil dilation/constriction were defined as the local maximum positive and negative values of the slope, separated by ≥ 200 ms (see Supplementary Figure 2) (Suzuki et al., 2022; Zhao et al., 2019). The pupil change velocity was computed between the latency of peak pupil dilation/constriction using the first derivative of pupillary change following which averaging the pupillary change in each VF and SOA condition.

We then calculated correlation coefficient () and significance levels by Spearman’s rank order correlations to assess the relationship between eye-metrics (pupil changes, pupil changes velocity, baseline pupil size, and gaze-fixation bias) and behavioral data (PSE and RT). 
\

### Statistical analysis
The averaged probability of participants answering whether the moving bar was perceived ahead of flashed bars was fit with a psychometric curve using a maximum-likelihood logistic function. We estimated a Point of Subjective Equality (PSE) as the probability of 0.5 in judging the moving bar as being to the left or right of the flashed bar. After collecting PSE data at LVF and RVF for all observers, we performed pairwise t-tests on PSEs between the visual fields. To statistically assess whether the FLI differed between VFs, the PSEs in each visual field were first bootstrapped 2000 times to estimate the mean and confidence interval. Mean pupillary changes were then subjected to a two-way repeated-measures analysis of variance (ANOVA) with VFs and Lags as the within-subject factor. 
Pairwise comparisons of the main effects were corrected through multiple comparisons using the Bonferroni-Holm method. The level of statistical significance was set to p < 0.05 for all analyses. Effect sizes were given as partial $\eta^2$; $\eta^2_p$ for ANOVAs and as Cohen’s $d_z$ for $t$-tests (Cohen, 1989). Greenhouse-Geisser corrections were performed when the results of Mauchly’s sphericity test were significant. To quantify the evidence in the data, we performed Bayesian paired t-tests and computed Bayes factors (BF) using a Cauchy prior width of r = 0.707 for effect size (v0.9.12-4.2) (Morey, 2018) for the R software (Version 3.6.3) (RCoreTeam, 2016). We reported Bayes Factor (BF) estimating the relative weight of the evidence in favor of $H_1$ over $H_0$ as $BF_{10}$.

To model the mean RT across SOA, we used a linear and nonlinear mixed-effects modeling with participants as a random effect to fit the data using the lme4 packages (Bates et al., 2015). In the analysis, we fitted the following two models to assess whether RT variability (Y) can be explained by SOA (X) using second-order polynomials or monotonic fitting.


Model 1 : $Y = \beta_0 + \beta_1X$

Model 2 : $Y = \beta_0 + \beta_1X + \beta_2X^2$


where $\beta$ as regression coefficients. The models were quantified using the Akaike information criterion (AIC), which specifies the evidence of the goodness of fit for a model.

